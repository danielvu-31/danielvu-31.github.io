<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Duc Vu</title>

    <meta name="author" content="Duc Vu">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,700|Roboto:400,700&display=swap">
    
  </head>

  <body>
    <header>
      <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr style="padding:0px">
          <td style="padding:0px">
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p class="name" style="text-align: center;">
                    Duc Vu
                  </p>

                  <p>
                    ðŸ«¶ Hi! I'm Duc. Nice to meet yall! ðŸ«¶ I am an AI research resident at 
                    <a href="https://www.qualcomm.com/">Qualcomm Research</a> in Vietnam, where I am fortunate to be supervised by 
                    <a href="https://scholar.google.com/citations?user=FYZ5ODQAAAAJ&hl=en">Dr. Anh Tran</a>.
                    Prior to this, I received my Bachelor of Science in Data Science & Statistics and Bachelor of Arts in Economics 
                    from Miami University - Oxford in the U.S (2024).</a>
                  </p>

                  <p style="text-align:center; font-weight:700; font-size:1.15em; margin-top:10px;">
                    I am seeking a PhD in Computer Science for Fall 2026 and excited to pursue impactful research. ðŸš€ðŸ“š
                  </p>

                  <p style="text-align:center">
                    <a href="mailto:duchongvu01@gmail.com">Email</a> &nbsp;/&nbsp;
                    <a href="data/CV.pdf">CV</a> &nbsp;/&nbsp;
                    <a href="https://scholar.google.co.in/citations?user=mUHCYJsAAAAJ&hl=en">Scholar</a> &nbsp;/&nbsp;
                    <a href="https://github.com/danielvu-31/">Github</a>
                  </p>
                </td>
                <td style="padding:2.5%; width: 25%; max-width: 25%;">
                  <a href="images/IMG_2901.png">
                    <img style="
                      width: 100%;
                      aspect-ratio: 4 / 5; /* A gentle portrait rectangle, not too long */
                      object-fit: cover;
                      object-position: center 75%;
                      border-radius: 12px; /* A nice, soft rounded corner */"
                      alt="profile photo"
                      src="images/IMG_2901.png"
                      class="hoverZoomLink">
                  </a>
                </td>
              </tr>
            </tbody></table>
          </td>
        </tr>
      </table>
    </header>

    <main>
      <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:16px;width:100%;vertical-align:middle">
              <h2>Research</h2>
              <p>
                My research focuses on advancing generative AI by leveraging <strong>efficient one-step generation for real-world applications </strong> such as video enhancement and image inpainting. I am particularly interested in diffusion-based methods that achieve high-quality results with minimal computational cost, making generative models more <strong>practical and accessible</strong>. In addition to efficiency, I am also working on <strong>adversarial defenses</strong> to ensure the <strong>responsible and safe deployment</strong> of generative video models. Looking ahead, I aim to expand my work toward <strong>multimodal and video generation</strong>, focusing on improving fine-grained temporal consistency and enhancing user-driven controllability.
              </p>
            </td>
          </tr>
      </tbody></table>

      <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:16px;width:100%;vertical-align:middle">
              <h2>Selected Preprints</h2>
              <p>
                <strong>* denotes equal contribution</strong>
              </p>
            </td>
          </tr>
      </tbody></table>
      <table style="width:100%;max-width:800px;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        
        <tr onmouseout="anti_stop()" onmouseover="anti_start()">
          <td style="padding:16px;width:20%;vertical-align:middle">
            <div class="one">
              <div class="two" id='anti_image'><video  width=100% muted autoplay loop>
              <source src="images/anti.mp4" type="video/mp4">
              Your browser does not support the video tag.
              </video></div>
              <img src='images/anti.jpg' width=100%>
            </div>
            <script type="text/javascript">
              function anti_start() {
                document.getElementById('anti_image').style.opacity = "1";
              }

              function anti_stop() {
                document.getElementById('anti_image').style.opacity = "0";
              }
              anti_stop()
            </script>
          </td>
          <td style="padding:8px;width:80%;vertical-align:middle">
            <a href="https://arxiv.org/abs/2510.21250">
              <span class="papertitle">Anti-I2V: Safeguarding your photos from malicious image-to-video generation.</span>
            </a>
            <br>
            <strong>Duc Vu</strong>,
            <a href="https://aengusng8.github.io/">Anh Nguyen</a>,
            Chi Tran,
            <a href="https://scholar.google.com/citations?user=FYZ5ODQAAAAJ&hl=en">Anh Tran</a>,
            <br>
            <em>Under Review</em>, 2025 &nbsp
            <br>
            <!-- <a href="https://arxiv.org/abs/2510.21250">ArXiv</a> -->
            <p></p>
            <p>
            A memoryâ€‘efficient adversarial attack against diverse imageâ€‘toâ€‘video diffusion models, enabled by robust dualâ€‘space perturbation optimization.
            </p>
          </td>
        </tr>

        <tr onmouseout="inverfill_stop()" onmouseover="inverfill_start()">
          <td style="padding:16px;width:20%;vertical-align:middle">
            <div class="one">
              <div class="two" id='inverfill_image'><video  width=100% muted autoplay loop>
              <source src="images/inverfill.mp4" type="video/mp4">
              Your browser does not support the video tag.
              </video></div>
              <img src='images/inverfill.png' width=100%>
            </div>
            <script type="text/javascript">
              function inverfill_start() {
                document.getElementById('inverfill_image').style.opacity = "1";
              }

              function inverfill_stop() {
                document.getElementById('inverfill_image').style.opacity = "0";
              }
              inverfill_stop()
            </script>
          </td>
          <td style="padding:8px;width:80%;vertical-align:middle">
            <a href="https://arxiv.org/abs/2510.21250">
              <span class="papertitle">InverFill: One-Step Inversion for Enhanced Few-Step Diffusion Inpainting.</span>
            </a>
            <br>
            <strong>Duc Vu*</strong>,
            Kien Nguyen*,
            <a href="https://nttung1110.github.io/">Trong-Tung Nguyen</a>,
            Ngan Nguyen,
            <a href="https://phongnhhn.info/">Phong Nguyen</a>,
            <a href="https://www.khoinguyen.org/">Khoi Nguyen</a>,
            <a href="https://sites.google.com/view/cuongpham/home/">Cuong Pham</a>,
            <a href="https://scholar.google.com/citations?user=FYZ5ODQAAAAJ&hl=en">Anh Tran</a>,
            <br>
            <em>Under Review</em>, 2025 &nbsp
            <br>
            <!-- <a href="https://arxiv.org/abs/2510.21250">ArXiv</a> -->
            <p></p>
            <p>
            A highly efficient one-step inversion diffusion network for high-quality few-step image inpainting.
            </p>
          </td>
        </tr>
        </tbody></table>

      <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:16px;width:100%;vertical-align:middle">
              <h2>Selected Publications</h2>
              <p>
                <strong>* denotes equal contribution</strong>
              </p>
            </td>
          </tr>
      </tbody></table>
      <table style="width:100%;max-width:800px;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr onmouseout="shortcut_stop()" onmouseover="shortcut_start()">
          <td style="padding:16px;width:20%;vertical-align:middle">
            <div class="one">
              <div class="two" id='shortcut_image'><video  width=100% muted autoplay loop>
              <source src="images/shortcut.mp4" type="video/mp4">
              Your browser does not support the video tag.
              </video></div>
              <img src='images/shortcut_before.png' width=100%>
            </div>
            <script type="text/javascript">
              function shortcut_start() {
                document.getElementById('shortcut_image').style.opacity = "1";
              }

              function shortcut_stop() {
                document.getElementById('shortcut_image').style.opacity = "0";
              }
              shortcut_stop()
            </script>
          </td>
          <td style="padding:8px;width:80%;vertical-align:middle">
            <a href="https://arxiv.org/abs/2510.21250">
              <span class="papertitle">Improved Training Technique for Shortcut Models.</span>
            </a>
            <br>
            <a href="https://aengusng8.github.io/">Anh Nguyen*</a>, 
            <a href="https://viettmab.github.io/">Viet Nguyen*</a>,
            <strong>Duc Vu</strong>,
            <a href="https://trung-dt.com/">Trung Dao</a>,
            Chi Tran,
            <a href="https://scholar.google.com.vn/citations?user=PnwSuNMAAAAJ&hl=vi">Toan Tran</a>,
            <a href="https://scholar.google.com/citations?user=FYZ5ODQAAAAJ&hl=en">Anh Tran</a>,
            <br>
            <em>NeurIPS</em>, 2025 &nbsp
            <br>
            <a href="https://arxiv.org/abs/2510.21250">ArXiv</a>
            <p></p>
            <p>
            iSM resolves five major shortcut-model flaws with dynamic guidance, wavelet loss, sOT, and Twin EMA, yielding markedly better image generation.
            </p>
          </td>
        </tr>

        <tr onmouseout="ever_stop()" onmouseover="ever_start()">
          <td style="padding:16px;width:20%;vertical-align:middle">
            <div class="one">
              <div class="two" id='ever_image'><video  width=100% muted autoplay loop>
              <source src="images/swiftbrushv2_after.mp4" type="video/mp4">
              Your browser does not support the video tag.
              </video></div>
              <img src='images/swiftbrushv2_before.jpg' width=100%>
            </div>
            <script type="text/javascript">
              function ever_start() {
                document.getElementById('ever_image').style.opacity = "1";
              }

              function ever_stop() {
                document.getElementById('ever_image').style.opacity = "0";
              }
              ever_stop()
            </script>
          </td>
          <td style="padding:8px;width:80%;vertical-align:middle">
            <a href="https://swiftbrushv2.github.io/">
              <span class="papertitle">SwiftBrush v2: Make Your One-step Diffusion Model Better Than Its Teacher.</span>
            </a>
            <br>
            <a href="https://trung-dt.com/">Trung Dao</a>, 
            <a href="https://thuanz123.github.io/">Thuan Hoang Nguyen*</a>,
            <a href="https://luvata.github.io/">Thanh Le*</a>,
            <strong>Duc Vu*</strong>,
            <a href="https://www.khoinguyen.org/">Khoi Nguyen</a>,
            <a href="https://sites.google.com/view/cuongpham/home/">Cuong Pham</a>,
            <a href="https://scholar.google.com/citations?user=FYZ5ODQAAAAJ&hl=en">Anh Tran</a>,
            <br>
            <em>ECCV</em>, 2024 &nbsp
            <br>
            <a href="https://swiftbrushv2.github.io/">Project page</a>
            /
            <a href="http://arxiv.org/abs/2408.14176">ArXiv</a>
            <p></p>
            <p>
            An improved SwiftBrush version that makes the one-step diffusion student beats its multi-step teacher.
            </p>
          </td>
        </tr>
        
        <tr onmouseout="efhq_stop()" onmouseover="efhq_start()">
          <td style="padding:16px;width:20%;vertical-align:middle">
            <div class="one">
              <div class="two" id='efhq_image'><video  width=100% muted autoplay loop>
              <source src="images/efhq_after.mp4" type="video/mp4">
              Your browser does not support the video tag.
              </video></div>
              <img src='images/efhq_before.png' width=100%>
            </div>
            <script type="text/javascript">
              function efhq_start() {
                document.getElementById('efhq_image').style.opacity = "1";
              }

              function efhq_stop() {
                document.getElementById('efhq_image').style.opacity = "0";
              }
              efhq_stop()
            </script>
          </td>
          <td style="padding:8px;width:80%;vertical-align:middle">
            <a href="https://vinairesearch.github.io/EFHQ/">
              <span class="papertitle">EFHQ: Multi-purpose ExtremePose-Face-HQ dataset.</span>
            </a>
            <br>
            <a href="https://trung-dt.com/">Trung Dao*</a>, 
            <strong>Duc Vu*</strong>,
            <a href="https://sites.google.com/view/cuongpham/home/">Cuong Pham</a>,
            <a href="https://scholar.google.com/citations?user=FYZ5ODQAAAAJ&hl=en">Anh Tran</a>,
            <br>
            <em>CVPR</em>, 2024 &nbsp
            <br>
            <a href="https://vinairesearch.github.io/EFHQ/">Project page</a>
            /
            <a href="https://arxiv.org/abs/2312.17205">ArXiv</a>
            <p></p>
            <p>
            A high-quality dataset centered on extreme pose faces, supporting face synthesis, reenactment, recognition benchmarking, and more.
            </p>
          </td>
        </tr>
      </tbody></table>
    </main>
  </body>
</html>
